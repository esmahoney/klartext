{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Hohenheimer Verständlichkeitsindex (HIX)*** is a German text comprehensibility/readability score designed to objectively compare how easy or hard a text is to understand.  ￼\n",
        "\n",
        "**How it works (high level)**\n",
        "\t•\tIt combines four readability formulas (validated for German): Amstad, 1st new Vienna factual-text formula, SMOG (German), and LIX.  ￼\n",
        "\t•\tIt also adds extra text features like average sentence length, average clause/segment length, average word length, and shares of very long words / clauses / sentences.  ￼\n",
        "\t•\tThose results are scaled and combined into a single score from 0 to 20 (higher = easier).  ￼\n",
        "\n",
        "**How to interpret the score (examples used in the method**\n",
        "\t•\tRoughly 0–5: comparable to a political science dissertation (expert-level).\n",
        "\t•\tRoughly 15–20: comparable to a tabloid-style newspaper article (very easy).  ￼\n",
        "\n",
        "**Practical note**\n",
        "\t•\tHIX is very useful for screening and tracking improvements, but it mainly measures surface features (length, structure, etc.), not whether the content is truly “Easy Language” for a specific audience.  ￼\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Turn the HIX approach into a practical, repeatable model-selection ruleset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Uncomment for training\n",
        "# import torch\n",
        "# from transformers import (\n",
        "#     AutoTokenizer,\n",
        "#     AutoModelForSeq2SeqLM,\n",
        "#     Seq2SeqTrainer,\n",
        "#     Seq2SeqTrainingArguments,\n",
        "#     DataCollatorForSeq2Seq,\n",
        "# )\n",
        "# from datasets import Dataset\n",
        "\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "\n",
        "print(f\"Data: {DATA_PROCESSED}\")\n",
        "print(f\"Models will be saved to: {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "CONFIG = {\n",
        "    # Model\n",
        "    \"base_model\": \"google/mt5-small\",  # or mt5-base, flan-t5-base\n",
        "    \"max_source_length\": 512,\n",
        "    \"max_target_length\": 256,\n",
        "    \n",
        "    # Training\n",
        "    \"batch_size\": 8,\n",
        "    \"learning_rate\": 5e-5,\n",
        "    \"num_epochs\": 3,\n",
        "    \"warmup_steps\": 500,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \n",
        "    # Outputs\n",
        "    \"output_dir\": str(MODELS_DIR / \"klartext-mt5-small\"),\n",
        "    \"logging_steps\": 100,\n",
        "    \"save_steps\": 500,\n",
        "    \"eval_steps\": 500,\n",
        "}\n",
        "\n",
        "print(\"Training config:\")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HIX setup \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Below is a web-sourced, concrete way to build your Negative (“hard”) and Target (“easy”) sets, plus Klartext guardrails and a HIX-style normalization scheme you can apply consistently across LLM outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Robust setup with real, existing texts**\n",
        "\n",
        "\n",
        "Negative set (“hard”): bureaucratic / academic German\n",
        "\n",
        "Use sources that are intentionally dense and publicly accessible.\n",
        "\n",
        "Bureaucratic / official\n",
        "\t•\tFederal laws & ordinances (consolidated text, free): “Gesetze im Internet” provides nearly all current German federal law for reuse (HTML/PDF/XML).  ￼\n",
        "\tExample = /Users/simonvoegely/Desktop/Klartext/klartext/data/samples/federal law text.txt\n",
        "\n",
        "•\tGood because: long sentences, nominal style, references, legal definitions.\n",
        "\n",
        "Academic / dissertation-style\n",
        "\t•\tHumboldt University edoc repository (Open Access PDFs): example dissertation pages with downloadable PDF files.  ￼\n",
        "\t•\tFU Berlin Refubium (Open Access dissertations, PDF download): example dissertation with PDF file listed.  \n",
        "\tExample = /Users/simonvoegely/Desktop/Klartext/klartext/data/samples/federal law text.txt\n",
        "\n",
        "Practical collection rule for the negative set:\n",
        "\t•\tSample across topics (law, health, politics, education) and formats (HTML pages + PDFs).\n",
        "\t•\tKeep the set “realistic”: use texts your users would actually face (letters, rules, laws, reports)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Target** ***set (“easy”): human-written “Einfache Sprache” samples***\n",
        "\n",
        "/Users/simonvoegely/Desktop/Klartext/klartext/data/samples/Nachrichten leicht.txt\n",
        "\n",
        "Curated directories of easy-language news sources\n",
        "\t•\tbpb “einfach POLITIK” list of easy/light news sources (helps you expand your target set without hunting blindly).  ￼\n",
        "\t•\tARD Digital overview of “Einfache und Leichte Sprache” offers (useful to add regional broadcasters as more target data).  ￼\n",
        "\n",
        "Research-grade parallel corpus (best for evaluation)\n",
        "\t•\tDEplain (parallel corpus: standard German ↔ plain German / “Einfache Sprache”): professionally written and aligned sentence/document pairs; available on Hugging Face + described in ACL paper.  ￼\n",
        "\n",
        "\t[DEplain: A German Parallel Corpus with Intralingual Translations into Plain Language for Sentence and Document Simplification](https://aclanthology.org/2023.acl-long.908/) (Stodden et al., ACL 2023)\n",
        "\n",
        "Minimum viable dataset recommendation (for stable model comparison):\n",
        "\t•\tNegative: 50–200 documents (laws + dissertations)\n",
        "\t•\tTarget: 50–200 documents (nachrichtenleicht + tagesschau easy + DEplain plain side)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***3. Ready-to-use guardrails aligned with Uni Hohenheim “Klartext”***\n",
        "\n",
        "Uni Hohenheim’s Klartext materials give you concrete, enforceable checks:\n",
        "\n",
        "Hard rule\n",
        "\t•\tSplit sentences longer than 20 words (track “% sentences > 20 words”).  ￼\n",
        "\n",
        "Style guardrails\n",
        "\t•\tAvoid passive and nominal style (prefer strong verbs).  ￼\n",
        "\t•\tAvoid very long/rare words; if unavoidable, explain briefly or use hyphens to show word parts.  ￼\n",
        "\t•\tKeep consistent wording and clear references (avoid switching terms).  ￼\n",
        "\n",
        "You can treat these as hard constraints in your evaluation: a model can have a good HIX-like score but still fail if it violates these rules too often."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. HIX-Style Normalization\n",
        "\n",
        "The HIX method uses a 3-step process: **benchmarking - scaling to 0-10 - combine to 0-20**\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5.1: Define Benchmarks from Your Corpora\n",
        "\n",
        "For each metric `m`, define two reference values:\n",
        "\n",
        "| Benchmark | Definition | Recommended Statistic |\n",
        "|-----------|------------|----------------------|\n",
        "| `target_m` | \"Good/Easy\" reference | Median (P50) or P25 for strict |\n",
        "| `neg_m` | \"Bad/Hard\" reference | Median (P50) or P75 for strict |\n",
        "\n",
        "**Why use corpus statistics?**\n",
        "- Avoids hand-picked arbitrary numbers\n",
        "- Keeps benchmarks stable across domains\n",
        "- Reproducible and defensible\n",
        "\n",
        "**Policy Options:**\n",
        "\n",
        "| Policy | Target | Negative | Use Case |\n",
        "|--------|--------|----------|----------|\n",
        "| **A (Balanced)** | P50(target) | P50(negative) | General comparison |\n",
        "| **B (Strict)** | P25(target) | P75(negative) | High-quality filtering |\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5.2: Scale Each Metric to 0-10\n",
        "\n",
        "Apply clamped linear scaling based on direction:\n",
        "\n",
        "**If LOWER is better** (sentence length, % long sentences, word length, clause length):\n",
        "\n",
        "`score_m = clamp( 10 * (neg_m - x) / (neg_m - target_m), 0, 10 )`\n",
        "\n",
        "**If HIGHER is better** (rare, but if defined that way):\n",
        "\n",
        "`score_m = clamp( 10 * (x - neg_m) / (target_m - neg_m), 0, 10 )`\n",
        "\n",
        "**Interpretation:**\n",
        "- `x = target_m` -> score = 10 (perfect)\n",
        "- `x = neg_m` -> score = 0 (worst)\n",
        "- Values outside range -> clamped to 0 or 10\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5.3: Combine to 0-20 HIX-like Index\n",
        "\n",
        "HIX combines two groups of scores:\n",
        "\n",
        "**Group 1: Readability Formulas (4 scores)**\n",
        "\n",
        "`S_formulas = mean(score_Amstad, score_Wiener, score_SMOG_DE, score_LIX)`\n",
        "\n",
        "**Group 2: Text Parameters (6 scores)**\n",
        "\n",
        "`S_params = mean(score_sentLen, score_clauseLen, score_wordLen, score_%words>6, score_%clauses>12, score_%sents>20)`\n",
        "\n",
        "**Final HIX-like Score:**\n",
        "\n",
        "`HIX_like = S_formulas + S_params`\n",
        "\n",
        "| Score Range | Interpretation |\n",
        "|-------------|----------------|\n",
        "| 0-5 | Expert-level (dissertation complexity) |\n",
        "| 6-10 | Moderate difficulty |\n",
        "| 11-15 | Accessible to general audience |\n",
        "| 16-20 | Easy Language / tabloid-style |\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5.4: Add Strictness Gates (Guardrails)\n",
        "\n",
        "**Independently from HIX_like score, enforce hard constraints:**\n",
        "\n",
        "| Gate | Threshold | Action if Failed |\n",
        "|------|-----------|------------------|\n",
        "| % sentences > 20 words | < 10% (from Target corpus) | REJECT model output |\n",
        "| Passive voice rate | < 15% | Flag for review |\n",
        "| Negation rate | < 10% | Flag for review |\n",
        "\n",
        "---\n",
        "\n",
        "### Summary: Complete Scoring Pipeline\n",
        "\n",
        "1. **COLLECT** - Freeze negative (hard) + target (easy) corpora\n",
        "2. **PREPROCESS** - Extract text, segment sentences/clauses\n",
        "3. **BENCHMARK** - Compute P50/P25/P75 for each metric on both corpora\n",
        "4. **SCALE** - For each model output, scale metrics to 0-10\n",
        "5. **COMBINE** - S_formulas + S_params = HIX_like (0-20)\n",
        "6. **GATE** - Check guardrails (reject if failed)\n",
        "7. **RANK** - Compare models by HIX_like + guardrail pass rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Implementation Roadmap\n",
        "\n",
        "A step-by-step guide to implement the HIX-based evaluation pipeline rigorously.\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 1: Dataset Tasks\n",
        "\n",
        "#### Step 1: Collect & Freeze Corpora\n",
        "\n",
        "| Corpus | Sources | Action |\n",
        "|--------|---------|--------|\n",
        "| **Negative (hard)** | Federal laws, dissertations, academic papers | Select URLs/PDFs and store snapshots locally |\n",
        "| **Target (easy)** | nachrichtenleicht, tagesschau easy, DEplain plain side | Download and version-control |\n",
        "\n",
        "**Key principle:** Freeze the corpus versions to ensure reproducible benchmarks.\n",
        "\n",
        "#### Step 2: Licensing & Reuse Check\n",
        "\n",
        "Create a metadata table for each source:\n",
        "\n",
        "| Source | License | Reuse Allowed | Notes |\n",
        "|--------|---------|---------------|-------|\n",
        "| Gesetze im Internet | Public Domain | ✅ Yes | German federal law |\n",
        "| DEplain | Open/Permission | ✅ Yes | ACL paper dataset |\n",
        "| nachrichtenleicht | Check ToS | ⚠️ Verify | News content |\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 2: Preprocessing Tasks\n",
        "\n",
        "#### Step 3: Text Extraction\n",
        "\n",
        "| Format | Tool/Method |\n",
        "|--------|-------------|\n",
        "| HTML | Boilerplate removal (trafilatura, BeautifulSoup) |\n",
        "| PDF | PyMuPDF, pdfplumber, or OCR if needed |\n",
        "| Plain text | Direct loading |\n",
        "\n",
        "#### Step 4: Segmentation\n",
        "\n",
        "Two levels of segmentation required:\n",
        "\n",
        "1. **Sentence splitting**\n",
        "   - Handle German punctuation rules\n",
        "   - Handle abbreviations (z.B., d.h., usw.)\n",
        "   - Tools: spaCy German, SoMaJo, or custom rules\n",
        "\n",
        "2. **Clause splitting**\n",
        "   - Split on subordinate clause markers (weil, dass, obwohl, wenn...)\n",
        "   - Required for computing \"Satzteillänge\" (clause length) like HIX\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 3: Metrics & Guardrail Tasks\n",
        "\n",
        "#### Step 5: Compute HIX Components\n",
        "\n",
        "**4 Readability Formulas:**\n",
        "\n",
        "| Formula | Description |\n",
        "|---------|-------------|\n",
        "| Amstad | German adaptation of Flesch Reading Ease |\n",
        "| 1st Vienna Formula | Austrian factual-text readability |\n",
        "| SMOG (German) | Simple Measure of Gobbledygook |\n",
        "| LIX | Läsbarhetsindex (Scandinavian origin) |\n",
        "\n",
        "**6 Text Parameters:**\n",
        "\n",
        "| Parameter | What it measures |\n",
        "|-----------|------------------|\n",
        "| Avg sentence length | Words per sentence |\n",
        "| Avg clause length | Words per clause/segment |\n",
        "| Avg word length | Characters per word |\n",
        "| % words > 6 chars | Share of long words |\n",
        "| % clauses > 12 words | Share of long clauses |\n",
        "| % sentences > 20 words | Share of very long sentences |\n",
        "\n",
        "#### Step 6: Compute Klartext Guardrail Metrics\n",
        "\n",
        "| Metric | Target | How to compute |\n",
        "|--------|--------|----------------|\n",
        "| % sentences > 20 words | < 10% | Count and divide |\n",
        "| Passive voice rate | < 15% | POS tagging + pattern matching |\n",
        "| Negation rate | < 10% | Count \"nicht\", \"kein\", \"nie\", etc. |\n",
        "| Terminology consistency | > 90% | Glossary hits / total terms |\n",
        "\n",
        "#### Step 7: Meaning Preservation Check\n",
        "\n",
        "Critical to avoid \"easy but wrong\" outputs:\n",
        "\n",
        "- **Human QA sampling:** Random sample review\n",
        "- **Rule-based checks:**\n",
        "  - Dates preserved correctly\n",
        "  - Numbers unchanged\n",
        "  - Obligations (must/may/shall) not altered\n",
        "  - Named entities intact\n",
        "\n",
        "---\n",
        "\n",
        "### Phase 4: Decision & Reporting Tasks\n",
        "\n",
        "#### Step 8: Model Evaluation Harness\n",
        "\n",
        "Standardize evaluation conditions:\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────┐\n",
        "│ EVALUATION HARNESS REQUIREMENTS         │\n",
        "├─────────────────────────────────────────┤\n",
        "│ ✓ Same system prompt for all models     │\n",
        "│ ✓ Same decoding settings (temp, top_p)  │\n",
        "│ ✓ Same test set (frozen)                │\n",
        "│ ✓ Versioned outputs (git/timestamps)    │\n",
        "│ ✓ Reproducible random seeds             │\n",
        "└─────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "#### Step 9: Score Dashboard\n",
        "\n",
        "Create a summary view with:\n",
        "\n",
        "| Metric | Display |\n",
        "|--------|---------|\n",
        "| Per-model scores | Median, IQR, min, max |\n",
        "| Guardrail pass/fail | Binary + violation count |\n",
        "| Error rate | % of failed generations |\n",
        "| HIX-like index | 0-20 scale |\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
