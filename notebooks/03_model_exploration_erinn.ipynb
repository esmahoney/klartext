{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b00741c",
   "metadata": {},
   "source": [
    "# Model baseline exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107147b",
   "metadata": {},
   "source": [
    "This notebook explores different models, prompts and inputs to find a good baseline. \n",
    "\n",
    "We are looking for a baseline that follows conventions laid out in /Users/esmahoney/Projects/klartext/klartext/notebooks/00_klartext_overview.ipynb \n",
    "\n",
    "The strategy is as follows: \n",
    "Step 1. Setup & Configuration - initialize Groq and list available models that are multilingual. \n",
    "2. Load dataset from \n",
    "\n",
    "| Dataset | Purpose | Metrics |\n",
    "|---------|---------|---------|\n",
    "| ASSET (EN) | Multi-reference evaluation | SARI, BLEU, FKGL |\n",
    "| TurkCorpus (EN) | Multi-reference evaluation | SARI, BLEU |\n",
    "| DEplain-test (DE) | German evaluation | SARI, BLEU |\n",
    "\n",
    "In this step we will evaluate models and provide a simplicity score from 1-10 \n",
    "\n",
    "Step 2. Exploration A: Prompt Strategy\n",
    "Step 3. Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6457264",
   "metadata": {},
   "source": [
    "# Step 1: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48760c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esmahoney/Projects/klartext/klartext/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for .env at: /Users/esmahoney/Projects/klartext/klartext/.env\n",
      "File exists: True\n",
      "âœ… API key loaded (starts with: gsk_VX1z...)\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path \n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "#Load API keys from project root .env file\n",
    "# The notebook is in /notebooks/, so we go up one level to find .env\n",
    "project_root = Path(__file__).parent.parent if '__file__' in dir() else Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "# Alternative: use explicit path\n",
    "env_path = Path(\"/Users/esmahoney/Projects/klartext/klartext/.env\")\n",
    "\n",
    "print(f\"Looking for .env at: {env_path}\")\n",
    "print(f\"File exists: {env_path.exists()}\")\n",
    "\n",
    "# Load from explicit path\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if api_key:\n",
    "    print(f\"âœ… API key loaded (starts with: {api_key[:8]}...)\")\n",
    "    client = Groq(api_key=api_key)\n",
    "else:\n",
    "    print(\"âŒ GROQ_API_KEY still not found!\")\n",
    "    print(f\"   Please ensure {env_path} contains: GROQ_API_KEY=gsk_...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfbe8238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Available Models on Groq:\n",
      "\n",
      "Model ID                                           Context    Owner          \n",
      "---------------------------------------------------------------------------\n",
      "whisper-large-v3                                   448        OpenAI         \n",
      "meta-llama/llama-prompt-guard-2-22m                512        Meta           \n",
      "meta-llama/llama-4-maverick-17b-128e-instruct      131072     Meta           \n",
      "playai-tts-arabic                                  8192       PlayAI         \n",
      "whisper-large-v3-turbo                             448        OpenAI         \n",
      "meta-llama/llama-prompt-guard-2-86m                512        Meta           \n",
      "allam-2-7b                                         4096       SDAIA          \n",
      "llama-3.3-70b-versatile                            131072     Meta           \n",
      "meta-llama/llama-4-scout-17b-16e-instruct          131072     Meta           \n",
      "meta-llama/llama-guard-4-12b                       131072     Meta           \n",
      "openai/gpt-oss-safeguard-20b                       131072     OpenAI         \n",
      "openai/gpt-oss-20b                                 131072     OpenAI         \n",
      "qwen/qwen3-32b                                     131072     Alibaba Cloud  \n",
      "playai-tts                                         8192       PlayAI         \n",
      "openai/gpt-oss-120b                                131072     OpenAI         \n",
      "groq/compound-mini                                 131072     Groq           \n",
      "moonshotai/kimi-k2-instruct-0905                   262144     Moonshot AI    \n",
      "llama-3.1-8b-instant                               131072     Meta           \n",
      "groq/compound                                      131072     Groq           \n",
      "moonshotai/kimi-k2-instruct                        131072     Moonshot AI    \n"
     ]
    }
   ],
   "source": [
    "# List Groq models and filter for multilingual capability\n",
    "models = client.models.list()\n",
    "\n",
    "print(\"ğŸ” Available Models on Groq:\\n\")\n",
    "print(f\"{'Model ID':<50} {'Context':<10} {'Owner':<15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for m in models.data:\n",
    "    print(f\"{m.id:<50} {m.context_window:<10} {m.owned_by:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda692a",
   "metadata": {},
   "source": [
    "Looking at these models and doing some research, we know that the best ones are:\n",
    "\n",
    "* qwen/qwen3-32b - specifically designed for multilingual tasks and has excellent German support. Strong instruction-following. Good balance of quality and speed. Best for DE/EN simplification\n",
    "* meta-llama/llama-4-maverick-17b-128e-instruct - Newest Llama 4 architecture. Mixture-of-Experts (MoE) means it's fast despite being capable. Good to compare against the Llama 3 models being tested for improvements.\n",
    "* moonshotai/kimi-k2-instruct - Different architecture/training from Meta/Alibaba. Known for strong reasoning and following complex instructions. Gives diversity to the baseline comparison. Good for testing a non-mainstream model for comparison.\n",
    "\n",
    "\n",
    "For follow-up additional exploration later: \n",
    "* groq/compound - This is Groq's own compound model â€” it likely routes requests to the best available model automatically. Interesting to see if it optimizes for your task. Best for \"Let the system choose\" baseline.     \n",
    "* allam-2-7b - Much smaller/faster model. Test if a lightweight model can handle simplification adequately â€” important for cost/speed trade-offs. Note: Primarily trained for Arabic; may have limited DE/EN quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13105a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Verifying models are available on Groq:\n",
      "  âœ… qwen/qwen3-32b\n",
      "  âœ… meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "  âœ… moonshotai/kimi-k2-instruct\n"
     ]
    }
   ],
   "source": [
    "MODELS_TO_TEST = [\n",
    "    \"qwen/qwen3-32b\",                              # Strong multilingual, good DE/EN\n",
    "    \"meta-llama/llama-4-maverick-17b-128e-instruct\",  # Latest Llama 4, 128K context\n",
    "    \"moonshotai/kimi-k2-instruct\",                 # Different architecture, strong reasoning\n",
    "]\n",
    "\n",
    "# Verify models are available\n",
    "print(\"ğŸ” Verifying models are available on Groq:\")\n",
    "available_model_ids = {m.id for m in client.models.list().data}\n",
    "\n",
    "for model in MODELS_TO_TEST:\n",
    "    status = \"âœ…\" if model in available_model_ids else \"âŒ NOT FOUND\"\n",
    "    print(f\"  {status} {model}\")\n",
    "\n",
    "LEVELS = [\"very_easy\", \"easy\", \"medium\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccff57",
   "metadata": {},
   "source": [
    "Step 2: Load Evaluation Datasets\n",
    "For this we will be using datasets from huggingface. Some of them only have full split available - meaning it is not available in test/train/validation splits and is only released in 1 big chunk, but this isn't a problem for our eval since we are not training.\n",
    "\n",
    "ASSET huggingface.co/datasets/asset, contains 2,359 sentences Ã— 10 simplified references each\n",
    "TurkCorpus huggingface.co/datasets/turkcorpus, contains 2,359 sentences Ã— 8 simplified references each\n",
    "DEplain-test huggingface.co/datasets/DEplain/DEplain-web, ~600K German sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcea9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ASSET...\n",
      "âœ… ASSET loaded: 50 examples\n",
      "   Fields: ['original', 'simplifications']\n",
      "\n",
      "Loading TurkCorpus...\n",
      "âœ… TurkCorpus loaded: 50 examples\n",
      "   Fields: ['gem_id', 'gem_parent_id', 'source', 'target', 'references']\n",
      "\n",
      "Loading DEplain...\n",
      "âœ… DEplain loaded: 50 examples\n",
      "   Fields: ['original', 'simplification', 'pair_id', 'complex_document_id', 'simple_document_id', 'domain', 'corpus', 'simple_url', 'complex_url', 'simple_level', 'complex_level', 'simple_location_html', 'complex_location_html', 'simple_location_txt', 'complex_location_txt', 'alignment_location', 'simple_author', 'complex_author', 'simple_title', 'complex_title', 'license', 'last_access']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# ============================================================\n",
    "# ASSET - English simplification benchmark\n",
    "# ============================================================\n",
    "# The \"ratings\" config only has a \"full\" split\n",
    "# Use \"simplification\" config for train/validation/test splits\n",
    "\n",
    "print(\"Loading ASSET...\")\n",
    "try:\n",
    "    # Option 1: Use \"simplification\" config (has validation split)\n",
    "    asset_data = load_dataset(\"asset\", \"simplification\", split=\"validation[:50]\")\n",
    "    print(f\"âœ… ASSET loaded: {len(asset_data)} examples\")\n",
    "    print(f\"   Fields: {asset_data.column_names}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ASSET error: {e}\")\n",
    "    # Fallback: use \"full\" split from ratings\n",
    "    asset_data = load_dataset(\"asset\", \"ratings\", split=\"full[:50]\")\n",
    "    print(f\"âœ… ASSET (ratings/full) loaded: {len(asset_data)} examples\")\n",
    "\n",
    "# ============================================================\n",
    "# TurkCorpus - English simplification  \n",
    "# ============================================================\n",
    "print(\"\\nLoading TurkCorpus...\")\n",
    "try:\n",
    "    turk_data = load_dataset(\"GEM/wiki_auto_asset_turk\", split=\"test_turk[:50]\") #use test_turk for full dataset this one has many splits this is the best for eval \n",
    "    print(f\"âœ… TurkCorpus loaded: {len(turk_data)} examples\")\n",
    "    print(f\"   Fields: {turk_data.column_names}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ TurkCorpus error: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# DEplain - German simplification\n",
    "# ============================================================\n",
    "print(\"\\nLoading DEplain...\")\n",
    "try:\n",
    "    deplain_data = load_dataset(\"DEplain/DEplain-web\", split=\"train[:50]\")\n",
    "    print(f\"âœ… DEplain loaded: {len(deplain_data)} examples\")\n",
    "    print(f\"   Fields: {deplain_data.column_names}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ DEplain error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90ee6b",
   "metadata": {},
   "source": [
    "Now we want to create Domain Specific test cases. This helps us differentiate from real world vs. wikipedia sentences - users will paste text from specific domains that have unique translation challenges. Often users won't paste wikipedia bt rather dense, bureaucratic texts.\n",
    "\n",
    "These help for the following:\n",
    "\n",
    "1. Standard benchmarks are limited like with ASSET and TurkCorpus. \n",
    "Dataset\tContent\tLimitation\n",
    "ASSET - Wikipedia sentences\tSimple factual statements, no legal/medical jargon\n",
    "TurkCorpus - Wikipedia sentences\tSame â€” general knowledge, easy vocabulary\n",
    "DEplain\t- German web content\tBetter, but may not cover all your target domains\n",
    "\n",
    "2. Better target toward user base\n",
    "Websites and documents often use complex language that excludes people with cognitive impairments, low literacy, dyslexia, seniors, and non-native speakers.\n",
    "The hard cases are:\n",
    "Legal â€” contracts, terms of service, government forms\n",
    "Medical â€” doctor letters, medication instructions, diagnosis reports\n",
    "Administrative â€” tax documents, immigration forms, official letters\n",
    "Financial â€” bank statements, insurance policies\n",
    "\n",
    "3. Better domain fit\n",
    "\"KlarText handles the kinds of texts that users actually paste (web, admin, health) better than a naÃ¯ve 'just prompt GPT' demo.\"\n",
    "To prove this claim, you need to test on those actual domains.\n",
    "\n",
    "4. Different domains have different failure modes that standard benchmarks won't catch these because they don't contain such text.\n",
    "* Legal - Model changes \"must\" to \"should\" (changes obligation), drops deadlines\n",
    "* Medical - Model simplifies dosage (\"2x daily\" â†’ \"regularly\"), misses warnings\n",
    "* Financial - Model drops amounts, changes percentages\n",
    "* Admin - Model misses deadlines, contact info, required documents\n",
    "\n",
    "5. German specific challenges\n",
    "German bureaucratic language (BehÃ¶rdendeutsch) has specific patterns and you often need German domain examples to test these:\n",
    "* Compound nouns: EinkommensteuererklÃ¤rung (income tax return)\n",
    "* Passive voice: Es wird darauf hingewiesen, dass...\n",
    "* Long nested sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f4b4e",
   "metadata": {},
   "source": [
    "How to use these tests:\n",
    "\n",
    "* Run simplification on each domain example\n",
    "* Check if critical elements are preserved (numbers, dates, obligations)\n",
    "* Compare models â€” which one handles legal text better?\n",
    "* Identify weaknesses â€” \"Model X always drops deadlines in German legal text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32ce915",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_EXAMPLES = [\n",
    "    {\"id\": \"de_legal\", \"text\": \"...\", \"lang\": \"de\", \"domain\": \"legal\"},\n",
    "    {\"id\": \"de_medical\", \"text\": \"...\", \"lang\": \"de\", \"domain\": \"medical\"},\n",
    "    {\"id\": \"en_legal\", \"text\": \"...\", \"lang\": \"en\", \"domain\": \"legal\"},\n",
    "    {\"id\": \"en_admin\", \"text\": \"...\", \"lang\": \"en\", \"domain\": \"administrative\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeedcae",
   "metadata": {},
   "source": [
    "Step 3: Define Prompt Templates\n",
    "\n",
    "This will use templates from prompts/templates/ but test variations:\n",
    "\n",
    "| Strategy      | Description                                         | Expected Behavior                    |\n",
    "|---------------|-----------------------------------------------------|--------------------------------------|\n",
    "| Generic       | \"Simplify this text\"                                | Baseline, may change structure       |\n",
    "| Level-Based   | Use simplify_en.txt / simplify_de.txt templates     | Controlled output by level           |\n",
    "| Lexical-Only  | Replace words, keep structure                       | Minimal structural change            |\n",
    "| ELI5          | Explain like I'm 5                                  | Maximum simplification               |\n",
    "| Structured    | Force bullet points + key points                    |                                      |\n",
    "\n",
    "We will test 5 different prompting strategies to see which produces the best simplifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f31f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(text: str, lang: str, level: str, strategy: str) -> str:\n",
    "    \"\"\"Build prompt based on strategy and level.\"\"\"\n",
    "    # Use templates from prompts/templates/\n",
    "    # Return system_prompt, user_content tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaed3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Defined 4 prompt strategies\n"
     ]
    }
   ],
   "source": [
    "# Define prompt strategies as Python strings\n",
    "PROMPT_STRATEGIES = {\n",
    "    \"generic\": \"Simplify this text for a general audience:\\n\\n{text}\",\n",
    "    \n",
    "    \"lexical_only\": \"\"\"Keep the exact same sentence structure.\n",
    "Only replace complex words with simpler synonyms.\n",
    "Do NOT add bullet points or change the structure.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Simplified:\"\"\",\n",
    "    \n",
    "    \"eli5\": \"Explain this like I am 5 years old:\\n\\n{text}\",\n",
    "    \n",
    "    \"structured\": \"\"\"Convert to a scannable format with:\n",
    "- 2-3 Key Points at the start\n",
    "- Headings and bullet points\n",
    "- Short sentences\n",
    "\n",
    "Text: {text}\"\"\",\n",
    "}\n",
    "\n",
    "print(f\"âœ… Defined {len(PROMPT_STRATEGIES)} prompt strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3dcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a prompt strategy\n",
    "strategy = \"eli5\"\n",
    "test_text = \"The implementation of regulatory frameworks...\"\n",
    "\n",
    "prompt = PROMPT_STRATEGIES[strategy].format(text=test_text)\n",
    "# Now send `prompt` to the Groq API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ae614",
   "metadata": {},
   "source": [
    "Step 4: Run Baseline Experiments\n",
    "\n",
    "| Dimension    | Values                        |\n",
    "|--------------|------------------------------|\n",
    "| Models       | 3 models                     |\n",
    "| Languages    | EN, DE                       |\n",
    "| Levels       | very_easy, easy, medium      |\n",
    "| Strategies   | 5 prompt strategies          |\n",
    "| Examples     | 50 per dataset               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c512cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test set created: 152 examples\n",
      "   Languages: {'en', 'de'}\n",
      "   Domains: {'legal', 'bible', 'wikipedia'}\n"
     ]
    }
   ],
   "source": [
    "#create test set\n",
    "# Combine datasets into a unified test set\n",
    "# Normalize field names across datasets\n",
    "\n",
    "test_set = []\n",
    "\n",
    "# Add ASSET examples (English)\n",
    "for item in asset_data:\n",
    "    test_set.append({\n",
    "        \"id\": f\"asset_{len(test_set)}\",\n",
    "        \"text\": item[\"original\"],\n",
    "        \"lang\": \"en\",\n",
    "        \"domain\": \"wikipedia\",\n",
    "        \"references\": item[\"simplifications\"]\n",
    "    })\n",
    "\n",
    "# Add TurkCorpus examples (English)\n",
    "for item in turk_data:\n",
    "    test_set.append({\n",
    "        \"id\": f\"turk_{len(test_set)}\",\n",
    "        \"text\": item[\"source\"],\n",
    "        \"lang\": \"en\",\n",
    "        \"domain\": \"wikipedia\",\n",
    "        \"references\": item[\"references\"]\n",
    "    })\n",
    "\n",
    "# Add DEplain examples (German)\n",
    "for item in deplain_data:\n",
    "    test_set.append({\n",
    "        \"id\": f\"deplain_{len(test_set)}\",\n",
    "        \"text\": item[\"original\"],\n",
    "        \"lang\": \"de\",\n",
    "        \"domain\": item.get(\"domain\", \"web\"),\n",
    "        \"references\": [item[\"simplification\"]]\n",
    "    })\n",
    "\n",
    "# Add domain-specific examples\n",
    "DOMAIN_EXAMPLES = [\n",
    "    {\n",
    "        \"id\": \"de_legal\",\n",
    "        \"text\": \"Der Antragsteller muss die erforderlichen Unterlagen innerhalb von 14 Tagen einreichen, andernfalls wird der Antrag abgelehnt.\",\n",
    "        \"lang\": \"de\",\n",
    "        \"domain\": \"legal\",\n",
    "        \"references\": []\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"en_legal\",\n",
    "        \"text\": \"The tenant shall vacate the premises no later than 30 days following written notice, failing which the landlord may pursue eviction proceedings.\",\n",
    "        \"lang\": \"en\",\n",
    "        \"domain\": \"legal\",\n",
    "        \"references\": []\n",
    "    },\n",
    "]\n",
    "test_set.extend(DOMAIN_EXAMPLES)\n",
    "\n",
    "print(f\"âœ… Test set created: {len(test_set)} examples\")\n",
    "print(f\"   Languages: {set(ex['lang'] for ex in test_set)}\")\n",
    "print(f\"   Domains: {set(ex['domain'] for ex in test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74c42fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(example: dict, model: str, level: str, strategy: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Call the LLM to simplify text.\n",
    "    Returns: (output_text, latency_ms)\n",
    "    \"\"\"\n",
    "    text = example[\"text\"]\n",
    "    lang = example[\"lang\"]\n",
    "    \n",
    "    # Build the prompt based on strategy\n",
    "    if strategy in PROMPT_STRATEGIES:\n",
    "        prompt = PROMPT_STRATEGIES[strategy].format(text=text)\n",
    "    else:\n",
    "        prompt = f\"Simplify this {lang} text:\\n\\n{text}\"\n",
    "    \n",
    "    # Add level instruction\n",
    "    level_instructions = {\n",
    "        \"very_easy\": \"Use very short sentences (max 10 words). Explain all difficult words.\",\n",
    "        \"easy\": \"Use short sentences (max 15 words). Keep it clear and simple.\",\n",
    "        \"medium\": \"Use plain language. Avoid jargon but keep normal sentence length.\"\n",
    "    }\n",
    "    \n",
    "    system_prompt = f\"You simplify text. Target level: {level}. {level_instructions.get(level, '')}\"\n",
    "    \n",
    "    # Call the API\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        latency_ms = (time.time() - start_time) * 1000\n",
    "        return output, latency_ms\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error with {model}: {e}\")\n",
    "        return f\"ERROR: {e}\", 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f589c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Running experiments:\n",
      "   Models: 3\n",
      "   Examples: 5\n",
      "   Levels: 3\n",
      "   Strategies: 4\n",
      "   Total API calls: 180\n",
      "\n",
      "\n",
      "ğŸ“Š Testing qwen/qwen3-32b...\n",
      "  âœ“ asset_0 | very_easy | generic | 1423ms\n",
      "  âœ“ asset_0 | very_easy | lexical_only | 1094ms\n",
      "  âœ“ asset_0 | very_easy | eli5 | 1094ms\n",
      "  âœ“ asset_0 | very_easy | structured | 1556ms\n",
      "  âœ“ asset_0 | easy | generic | 1000ms\n",
      "  âœ“ asset_0 | easy | lexical_only | 3519ms\n",
      "  âœ“ asset_0 | easy | eli5 | 810ms\n",
      "  âœ“ asset_0 | easy | structured | 1890ms\n",
      "  âœ“ asset_0 | medium | generic | 1533ms\n",
      "  âœ“ asset_0 | medium | lexical_only | 910ms\n",
      "  âœ“ asset_0 | medium | eli5 | 2329ms\n",
      "  âœ“ asset_0 | medium | structured | 1537ms\n",
      "  âœ“ asset_1 | very_easy | generic | 2920ms\n",
      "  âœ“ asset_1 | very_easy | lexical_only | 2681ms\n",
      "  âœ“ asset_1 | very_easy | eli5 | 1941ms\n",
      "  âœ“ asset_1 | very_easy | structured | 2714ms\n",
      "  âœ“ asset_1 | easy | generic | 2124ms\n",
      "  âœ“ asset_1 | easy | lexical_only | 1778ms\n",
      "  âœ“ asset_1 | easy | eli5 | 1885ms\n",
      "  âœ“ asset_1 | easy | structured | 3364ms\n",
      "  âœ“ asset_1 | medium | generic | 1912ms\n",
      "  âœ“ asset_1 | medium | lexical_only | 1871ms\n",
      "  âœ“ asset_1 | medium | eli5 | 1949ms\n",
      "  âœ“ asset_1 | medium | structured | 3182ms\n",
      "  âœ“ asset_2 | very_easy | generic | 2254ms\n",
      "  âœ“ asset_2 | very_easy | lexical_only | 3023ms\n",
      "  âœ“ asset_2 | very_easy | eli5 | 2636ms\n",
      "  âœ“ asset_2 | very_easy | structured | 4002ms\n",
      "  âœ“ asset_2 | easy | generic | 2190ms\n",
      "  âœ“ asset_2 | easy | lexical_only | 3095ms\n",
      "  âœ“ asset_2 | easy | eli5 | 2194ms\n",
      "  âœ“ asset_2 | easy | structured | 3276ms\n",
      "  âœ“ asset_2 | medium | generic | 1855ms\n",
      "  âœ“ asset_2 | medium | lexical_only | 3528ms\n",
      "  âœ“ asset_2 | medium | eli5 | 2494ms\n",
      "  âœ“ asset_2 | medium | structured | 2350ms\n",
      "  âœ“ asset_3 | very_easy | generic | 4544ms\n",
      "  âœ“ asset_3 | very_easy | lexical_only | 2139ms\n",
      "  âœ“ asset_3 | very_easy | eli5 | 2294ms\n",
      "  âœ“ asset_3 | very_easy | structured | 3089ms\n",
      "  âœ“ asset_3 | easy | generic | 2254ms\n",
      "  âœ“ asset_3 | easy | lexical_only | 1909ms\n",
      "  âœ“ asset_3 | easy | eli5 | 2880ms\n",
      "  âœ“ asset_3 | easy | structured | 3628ms\n",
      "  âœ“ asset_3 | medium | generic | 2779ms\n",
      "  âœ“ asset_3 | medium | lexical_only | 1940ms\n",
      "  âœ“ asset_3 | medium | eli5 | 2014ms\n",
      "  âœ“ asset_3 | medium | structured | 2064ms\n",
      "  âœ“ asset_4 | very_easy | generic | 1723ms\n",
      "  âœ“ asset_4 | very_easy | lexical_only | 2167ms\n",
      "  âœ“ asset_4 | very_easy | eli5 | 1890ms\n",
      "  âœ“ asset_4 | very_easy | structured | 2413ms\n",
      "  âœ“ asset_4 | easy | generic | 2013ms\n",
      "  âœ“ asset_4 | easy | lexical_only | 1715ms\n",
      "  âœ“ asset_4 | easy | eli5 | 1708ms\n",
      "  âœ“ asset_4 | easy | structured | 3520ms\n",
      "  âœ“ asset_4 | medium | generic | 1617ms\n",
      "  âœ“ asset_4 | medium | lexical_only | 2028ms\n",
      "  âœ“ asset_4 | medium | eli5 | 2260ms\n",
      "  âœ“ asset_4 | medium | structured | 26413ms\n",
      "\n",
      "ğŸ“Š Testing meta-llama/llama-4-maverick-17b-128e-instruct...\n",
      "  âœ“ asset_0 | very_easy | generic | 1852ms\n",
      "  âœ“ asset_0 | very_easy | lexical_only | 1368ms\n",
      "  âœ“ asset_0 | very_easy | eli5 | 3019ms\n",
      "  âœ“ asset_0 | very_easy | structured | 1123ms\n",
      "  âœ“ asset_0 | easy | generic | 276ms\n",
      "  âœ“ asset_0 | easy | lexical_only | 390ms\n",
      "  âœ“ asset_0 | easy | eli5 | 563ms\n",
      "  âœ“ asset_0 | easy | structured | 469ms\n",
      "  âœ“ asset_0 | medium | generic | 1159ms\n",
      "  âœ“ asset_0 | medium | lexical_only | 872ms\n",
      "  âœ“ asset_0 | medium | eli5 | 1061ms\n",
      "  âœ“ asset_0 | medium | structured | 507ms\n",
      "  âœ“ asset_1 | very_easy | generic | 938ms\n",
      "  âœ“ asset_1 | very_easy | lexical_only | 1640ms\n",
      "  âœ“ asset_1 | very_easy | eli5 | 1300ms\n",
      "  âœ“ asset_1 | very_easy | structured | 1430ms\n",
      "  âœ“ asset_1 | easy | generic | 650ms\n",
      "  âœ“ asset_1 | easy | lexical_only | 521ms\n",
      "  âœ“ asset_1 | easy | eli5 | 1535ms\n",
      "  âœ“ asset_1 | easy | structured | 335ms\n",
      "  âœ“ asset_1 | medium | generic | 160ms\n",
      "  âœ“ asset_1 | medium | lexical_only | 621ms\n",
      "  âœ“ asset_1 | medium | eli5 | 256ms\n",
      "  âœ“ asset_1 | medium | structured | 278ms\n",
      "  âœ“ asset_2 | very_easy | generic | 371ms\n",
      "  âœ“ asset_2 | very_easy | lexical_only | 242ms\n",
      "  âœ“ asset_2 | very_easy | eli5 | 595ms\n",
      "  âœ“ asset_2 | very_easy | structured | 360ms\n",
      "  âœ“ asset_2 | easy | generic | 184ms\n",
      "  âœ“ asset_2 | easy | lexical_only | 186ms\n",
      "  âœ“ asset_2 | easy | eli5 | 195ms\n",
      "  âœ“ asset_2 | easy | structured | 2377ms\n",
      "  âœ“ asset_2 | medium | generic | 2419ms\n",
      "  âœ“ asset_2 | medium | lexical_only | 2228ms\n",
      "  âœ“ asset_2 | medium | eli5 | 2517ms\n",
      "  âœ“ asset_2 | medium | structured | 2538ms\n",
      "  âœ“ asset_3 | very_easy | generic | 2561ms\n",
      "  âœ“ asset_3 | very_easy | lexical_only | 4249ms\n",
      "  âœ“ asset_3 | very_easy | eli5 | 1587ms\n",
      "  âœ“ asset_3 | very_easy | structured | 2394ms\n",
      "  âœ“ asset_3 | easy | generic | 2235ms\n",
      "  âœ“ asset_3 | easy | lexical_only | 2230ms\n",
      "  âœ“ asset_3 | easy | eli5 | 2234ms\n",
      "  âœ“ asset_3 | easy | structured | 2387ms\n",
      "  âœ“ asset_3 | medium | generic | 2539ms\n",
      "  âœ“ asset_3 | medium | lexical_only | 2359ms\n",
      "  âœ“ asset_3 | medium | eli5 | 2300ms\n",
      "  âœ“ asset_3 | medium | structured | 2346ms\n",
      "  âœ“ asset_4 | very_easy | generic | 2255ms\n",
      "  âœ“ asset_4 | very_easy | lexical_only | 2285ms\n",
      "  âœ“ asset_4 | very_easy | eli5 | 2269ms\n",
      "  âœ“ asset_4 | very_easy | structured | 2382ms\n",
      "  âœ“ asset_4 | easy | generic | 2521ms\n",
      "  âœ“ asset_4 | easy | lexical_only | 2209ms\n",
      "  âœ“ asset_4 | easy | eli5 | 2233ms\n",
      "  âœ“ asset_4 | easy | structured | 2441ms\n",
      "  âœ“ asset_4 | medium | generic | 2662ms\n",
      "  âœ“ asset_4 | medium | lexical_only | 2221ms\n",
      "  âœ“ asset_4 | medium | eli5 | 2697ms\n",
      "  âœ“ asset_4 | medium | structured | 3024ms\n",
      "\n",
      "ğŸ“Š Testing moonshotai/kimi-k2-instruct...\n",
      "  âœ“ asset_0 | very_easy | generic | 4248ms\n",
      "  âœ“ asset_0 | very_easy | lexical_only | 1595ms\n",
      "  âœ“ asset_0 | very_easy | eli5 | 2470ms\n",
      "  âœ“ asset_0 | very_easy | structured | 4216ms\n",
      "âŒ Error with moonshotai/kimi-k2-instruct: Error code: 503 - {'error': {'message': 'moonshotai/kimi-k2-instruct is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.', 'type': 'internal_server_error'}}\n",
      "  âœ“ asset_0 | easy | generic | 0ms\n",
      "  âœ“ asset_0 | easy | lexical_only | 1264ms\n",
      "  âœ“ asset_0 | easy | eli5 | 756ms\n",
      "  âœ“ asset_0 | easy | structured | 2724ms\n",
      "  âœ“ asset_0 | medium | generic | 597ms\n",
      "  âœ“ asset_0 | medium | lexical_only | 1379ms\n",
      "  âœ“ asset_0 | medium | eli5 | 1220ms\n",
      "  âœ“ asset_0 | medium | structured | 2920ms\n",
      "âŒ Error with moonshotai/kimi-k2-instruct: Error code: 503 - {'error': {'message': 'moonshotai/kimi-k2-instruct is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.', 'type': 'internal_server_error'}}\n",
      "  âœ“ asset_1 | very_easy | generic | 0ms\n",
      "âŒ Error with moonshotai/kimi-k2-instruct: Error code: 503 - {'error': {'message': 'moonshotai/kimi-k2-instruct is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.', 'type': 'internal_server_error'}}\n",
      "  âœ“ asset_1 | very_easy | lexical_only | 0ms\n",
      "  âœ“ asset_1 | very_easy | eli5 | 1689ms\n",
      "  âœ“ asset_1 | very_easy | structured | 2728ms\n",
      "  âœ“ asset_1 | easy | generic | 1460ms\n",
      "  âœ“ asset_1 | easy | lexical_only | 1054ms\n",
      "  âœ“ asset_1 | easy | eli5 | 1510ms\n",
      "  âœ“ asset_1 | easy | structured | 1840ms\n",
      "  âœ“ asset_1 | medium | generic | 933ms\n",
      "  âœ“ asset_1 | medium | lexical_only | 713ms\n",
      "  âœ“ asset_1 | medium | eli5 | 912ms\n",
      "  âœ“ asset_1 | medium | structured | 676ms\n",
      "  âœ“ asset_2 | very_easy | generic | 540ms\n",
      "  âœ“ asset_2 | very_easy | lexical_only | 622ms\n",
      "  âœ“ asset_2 | very_easy | eli5 | 466ms\n",
      "  âœ“ asset_2 | very_easy | structured | 674ms\n",
      "  âœ“ asset_2 | easy | generic | 459ms\n",
      "  âœ“ asset_2 | easy | lexical_only | 371ms\n",
      "  âœ“ asset_2 | easy | eli5 | 450ms\n",
      "  âœ“ asset_2 | easy | structured | 588ms\n",
      "  âœ“ asset_2 | medium | generic | 410ms\n",
      "  âœ“ asset_2 | medium | lexical_only | 391ms\n",
      "  âœ“ asset_2 | medium | eli5 | 458ms\n",
      "  âœ“ asset_2 | medium | structured | 569ms\n",
      "  âœ“ asset_3 | very_easy | generic | 593ms\n",
      "  âœ“ asset_3 | very_easy | lexical_only | 398ms\n",
      "  âœ“ asset_3 | very_easy | eli5 | 448ms\n",
      "  âœ“ asset_3 | very_easy | structured | 656ms\n",
      "  âœ“ asset_3 | easy | generic | 911ms\n",
      "  âœ“ asset_3 | easy | lexical_only | 391ms\n",
      "  âœ“ asset_3 | easy | eli5 | 352ms\n",
      "  âœ“ asset_3 | easy | structured | 820ms\n",
      "  âœ“ asset_3 | medium | generic | 635ms\n",
      "  âœ“ asset_3 | medium | lexical_only | 488ms\n",
      "  âœ“ asset_3 | medium | eli5 | 726ms\n",
      "  âœ“ asset_3 | medium | structured | 1214ms\n",
      "  âœ“ asset_4 | very_easy | generic | 802ms\n",
      "  âœ“ asset_4 | very_easy | lexical_only | 1093ms\n",
      "  âœ“ asset_4 | very_easy | eli5 | 582ms\n",
      "  âœ“ asset_4 | very_easy | structured | 1935ms\n",
      "  âœ“ asset_4 | easy | generic | 353ms\n",
      "  âœ“ asset_4 | easy | lexical_only | 586ms\n",
      "  âœ“ asset_4 | easy | eli5 | 1392ms\n",
      "  âœ“ asset_4 | easy | structured | 824ms\n",
      "  âœ“ asset_4 | medium | generic | 566ms\n",
      "  âœ“ asset_4 | medium | lexical_only | 345ms\n",
      "  âœ“ asset_4 | medium | eli5 | 906ms\n",
      "  âœ“ asset_4 | medium | structured | 1032ms\n",
      "\n",
      "âœ… Completed 180 experiments\n"
     ]
    }
   ],
   "source": [
    "# Run experiments with logging\n",
    "results = []\n",
    "STRATEGIES = list(PROMPT_STRATEGIES.keys())  # [\"generic\", \"lexical_only\", \"eli5\", \"structured\"]\n",
    "\n",
    "# Limit test set for initial testing (remove [:5] for full run)\n",
    "test_subset = test_set[:5]\n",
    "\n",
    "print(f\"ğŸ§ª Running experiments:\")\n",
    "print(f\"   Models: {len(MODELS_TO_TEST)}\")\n",
    "print(f\"   Examples: {len(test_subset)}\")\n",
    "print(f\"   Levels: {len(LEVELS)}\")\n",
    "print(f\"   Strategies: {len(STRATEGIES)}\")\n",
    "print(f\"   Total API calls: {len(MODELS_TO_TEST) * len(test_subset) * len(LEVELS) * len(STRATEGIES)}\")\n",
    "print()\n",
    "\n",
    "for model in MODELS_TO_TEST:\n",
    "    print(f\"\\nğŸ“Š Testing {model}...\")\n",
    "    for example in test_subset:\n",
    "        for level in LEVELS:\n",
    "            for strategy in STRATEGIES:\n",
    "                output, elapsed = simplify(example, model, level, strategy)\n",
    "                results.append({\n",
    "                    \"model\": model,\n",
    "                    \"example_id\": example[\"id\"],\n",
    "                    \"input\": example[\"text\"][:100] + \"...\",  # Truncate for storage\n",
    "                    \"output\": output,\n",
    "                    \"level\": level,\n",
    "                    \"strategy\": strategy,\n",
    "                    \"lang\": example[\"lang\"],\n",
    "                    \"domain\": example[\"domain\"],\n",
    "                    \"latency_ms\": elapsed,\n",
    "                })\n",
    "                print(f\"  âœ“ {example['id']} | {level} | {strategy} | {elapsed:.0f}ms\")\n",
    "\n",
    "print(f\"\\nâœ… Completed {len(results)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42be2ee",
   "metadata": {},
   "source": [
    "Alright, super cool we have a lot of... stuff and a groq dashboard that indicates this almost had us hit our rate limit. But, what does this mean, I need some simple text to figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca9479ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Collected 180 results\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>example_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>level</th>\n",
       "      <th>strategy</th>\n",
       "      <th>lang</th>\n",
       "      <th>domain</th>\n",
       "      <th>latency_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user wants me to...</td>\n",
       "      <td>very_easy</td>\n",
       "      <td>generic</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1423.298120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user wants me to...</td>\n",
       "      <td>very_easy</td>\n",
       "      <td>lexical_only</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1093.714952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user wants me to explain th...</td>\n",
       "      <td>very_easy</td>\n",
       "      <td>eli5</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1093.952179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user wants me to convert th...</td>\n",
       "      <td>very_easy</td>\n",
       "      <td>structured</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1555.933237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user wants me to...</td>\n",
       "      <td>easy</td>\n",
       "      <td>generic</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>999.747753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user wants me to...</td>\n",
       "      <td>easy</td>\n",
       "      <td>lexical_only</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>3518.867016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user wants me to explain th...</td>\n",
       "      <td>easy</td>\n",
       "      <td>eli5</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>810.487986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user wants me to convert th...</td>\n",
       "      <td>easy</td>\n",
       "      <td>structured</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1889.706135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user wants me to...</td>\n",
       "      <td>medium</td>\n",
       "      <td>generic</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1533.195972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>asset_0</td>\n",
       "      <td>Adjacent counties are Marin (to the south), Me...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user wants me to...</td>\n",
       "      <td>medium</td>\n",
       "      <td>lexical_only</td>\n",
       "      <td>en</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>909.666777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model example_id  \\\n",
       "0  qwen/qwen3-32b    asset_0   \n",
       "1  qwen/qwen3-32b    asset_0   \n",
       "2  qwen/qwen3-32b    asset_0   \n",
       "3  qwen/qwen3-32b    asset_0   \n",
       "4  qwen/qwen3-32b    asset_0   \n",
       "5  qwen/qwen3-32b    asset_0   \n",
       "6  qwen/qwen3-32b    asset_0   \n",
       "7  qwen/qwen3-32b    asset_0   \n",
       "8  qwen/qwen3-32b    asset_0   \n",
       "9  qwen/qwen3-32b    asset_0   \n",
       "\n",
       "                                               input  \\\n",
       "0  Adjacent counties are Marin (to the south), Me...   \n",
       "1  Adjacent counties are Marin (to the south), Me...   \n",
       "2  Adjacent counties are Marin (to the south), Me...   \n",
       "3  Adjacent counties are Marin (to the south), Me...   \n",
       "4  Adjacent counties are Marin (to the south), Me...   \n",
       "5  Adjacent counties are Marin (to the south), Me...   \n",
       "6  Adjacent counties are Marin (to the south), Me...   \n",
       "7  Adjacent counties are Marin (to the south), Me...   \n",
       "8  Adjacent counties are Marin (to the south), Me...   \n",
       "9  Adjacent counties are Marin (to the south), Me...   \n",
       "\n",
       "                                              output      level      strategy  \\\n",
       "0  <think>\\nOkay, let's see. The user wants me to...  very_easy       generic   \n",
       "1  <think>\\nOkay, let's see. The user wants me to...  very_easy  lexical_only   \n",
       "2  <think>\\nOkay, the user wants me to explain th...  very_easy          eli5   \n",
       "3  <think>\\nOkay, the user wants me to convert th...  very_easy    structured   \n",
       "4  <think>\\nOkay, let's see. The user wants me to...       easy       generic   \n",
       "5  <think>\\nOkay, let's see. The user wants me to...       easy  lexical_only   \n",
       "6  <think>\\nOkay, the user wants me to explain th...       easy          eli5   \n",
       "7  <think>\\nOkay, the user wants me to convert th...       easy    structured   \n",
       "8  <think>\\nOkay, let's see. The user wants me to...     medium       generic   \n",
       "9  <think>\\nOkay, let's see. The user wants me to...     medium  lexical_only   \n",
       "\n",
       "  lang     domain   latency_ms  \n",
       "0   en  wikipedia  1423.298120  \n",
       "1   en  wikipedia  1093.714952  \n",
       "2   en  wikipedia  1093.952179  \n",
       "3   en  wikipedia  1555.933237  \n",
       "4   en  wikipedia   999.747753  \n",
       "5   en  wikipedia  3518.867016  \n",
       "6   en  wikipedia   810.487986  \n",
       "7   en  wikipedia  1889.706135  \n",
       "8   en  wikipedia  1533.195972  \n",
       "9   en  wikipedia   909.666777  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#view results as a table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"ğŸ“Š Collected {len(results_df)} results\\n\")\n",
    "\n",
    "# Show first few rows\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe1869",
   "metadata": {},
   "source": [
    "Hmmm... wtf is this even telling me?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b34477e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ Latency by Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg (ms)</th>\n",
       "      <th>Min (ms)</th>\n",
       "      <th>Max (ms)</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-4-maverick-17b-128e-instruct</th>\n",
       "      <td>1586.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4249.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonshotai/kimi-k2-instruct</th>\n",
       "      <td>1016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4248.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-32b</th>\n",
       "      <td>2682.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>26413.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Avg (ms)  Min (ms)  Max (ms)  \\\n",
       "model                                                                         \n",
       "meta-llama/llama-4-maverick-17b-128e-instruct    1586.0     160.0    4249.0   \n",
       "moonshotai/kimi-k2-instruct                      1016.0       0.0    4248.0   \n",
       "qwen/qwen3-32b                                   2682.0     810.0   26413.0   \n",
       "\n",
       "                                               Count  \n",
       "model                                                 \n",
       "meta-llama/llama-4-maverick-17b-128e-instruct     60  \n",
       "moonshotai/kimi-k2-instruct                       60  \n",
       "qwen/qwen3-32b                                    60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Average latency by model\n",
    "model_summary = results_df.groupby(\"model\").agg({\n",
    "    \"latency_ms\": [\"mean\", \"min\", \"max\", \"count\"]\n",
    "}).round(0)\n",
    "model_summary.columns = [\"Avg (ms)\", \"Min (ms)\", \"Max (ms)\", \"Count\"]\n",
    "\n",
    "print(\"â±ï¸ Latency by Model:\")\n",
    "display(model_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad4956",
   "metadata": {},
   "source": [
    "Oh god, great... not better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b823a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Results by Strategy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg Latency (ms)</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eli5</th>\n",
       "      <td>1535.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generic</th>\n",
       "      <td>1498.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexical_only</th>\n",
       "      <td>1505.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structured</th>\n",
       "      <td>2507.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Avg Latency (ms)  Count\n",
       "strategy                             \n",
       "eli5                    1535.0     45\n",
       "generic                 1498.0     45\n",
       "lexical_only            1505.0     45\n",
       "structured              2507.0     45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Average latency by strategy\n",
    "strategy_summary = results_df.groupby(\"strategy\").agg({\n",
    "    \"latency_ms\": [\"mean\", \"count\"]\n",
    "}).round(0)\n",
    "strategy_summary.columns = [\"Avg Latency (ms)\", \"Count\"]\n",
    "\n",
    "print(\"\\nğŸ“ Results by Strategy:\")\n",
    "display(strategy_summary)\n",
    "\n",
    "# Average latency by level\n",
    "level_summary = results_df.groupby(\"level\").agg({\n",
    "    \"latency_ms\": [\"mean\", \"count\"]\n",
    "}).round(0)\n",
    "level_summary.columns = [\"Avg Latency (ms)\", \"Count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439b03c",
   "metadata": {},
   "source": [
    "What hellhole did I end up in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1d26e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“„ Example: asset_0 | Level: easy\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¹ ORIGINAL:\n",
      "Adjacent counties are Marin (to the south), Mendocino (to the north), Lake (northeast), Napa (to the...\n",
      "\n",
      "\n",
      "ğŸ”¸ qwen3-32b | generic\n",
      "   Latency: 1000ms\n",
      "   Output: <think>\n",
      "Okay, let's see. The user wants me to simplify this text about adjacent counties. The original sentence lists several counties with their directions relative to the main one.\n",
      "\n",
      "First, I need to make sure the directions are clear. The original uses \"to the south,\" \"to the north,\" etc. Maybe I ...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ qwen3-32b | lexical_only\n",
      "   Latency: 3519ms\n",
      "   Output: <think>\n",
      "Okay, let's see. The user wants me to simplify the given text. The original sentence lists adjacent counties with their directions. The task is to replace complex words with simpler synonyms while keeping the same structure.\n",
      "\n",
      "First, \"adjacent\" can be \"next to\" or \"near.\" But \"adjacent\" is al...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ qwen3-32b | eli5\n",
      "   Latency: 810ms\n",
      "   Output: <think>\n",
      "Okay, the user wants me to explain the original sentence as if I'm talking to a 5-year-old. Let me start by breaking down the original text. It lists several counties adjacent to a main county, each with their direction. The user probably wants a simple explanation without complex words.\n",
      "\n",
      "Fi...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ qwen3-32b | structured\n",
      "   Latency: 1890ms\n",
      "   Output: <think>\n",
      "Okay, the user wants me to convert the given text into a scannable format. Let me start by understanding the original text. It lists adjacent counties with their directions. The key points should be at the start. Maybe the main point is the list of counties and their directions.\n",
      "\n",
      "First, I ne...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | generic\n",
      "   Latency: 276ms\n",
      "   Output: The county is near these counties: Marin, Mendocino, Lake, Napa, Solano, and Contra Costa....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | lexical_only\n",
      "   Latency: 390ms\n",
      "   Output: Nearby counties are Marin (south), Mendocino (north), Lake (northeast), Napa (east), and Solano and Contra Costa (southeast)....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | eli5\n",
      "   Latency: 563ms\n",
      "   Output: Here are the neighbors of this place:\n",
      "\n",
      "* Marin is below it.\n",
      "* Mendocino is above it.\n",
      "* Lake is above and to the right.\n",
      "* Napa is to the right.\n",
      "* Solano and Contra Costa are below and to the right....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | structured\n",
      "   Latency: 469ms\n",
      "   Output: **Key Points:**\n",
      "* Sonoma County is surrounded by several counties.\n",
      "* The counties are located in different directions.\n",
      "* They share borders with Sonoma County.\n",
      "\n",
      "**Counties Bordering Sonoma County**\n",
      "\n",
      "* To the:\n",
      "\t+ South: Marin County\n",
      "\t+ North: Mendocino County\n",
      "\t+ Northeast: Lake County\n",
      "\t+ East: Napa C...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | generic\n",
      "   Latency: 0ms\n",
      "   Output: ERROR: Error code: 503 - {'error': {'message': 'moonshotai/kimi-k2-instruct is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.', 'type': 'internal_server_error'}}...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | lexical_only\n",
      "   Latency: 1264ms\n",
      "   Output: Nearby counties are Marin (to the south), Mendocino (to the north), Lake (northeast), Napa (to the east), and Solano and Contra Costa (to the southeast)....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | eli5\n",
      "   Latency: 756ms\n",
      "   Output: Think of counties like big puzzle pieces.  \n",
      "The county touches six pieces around it....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | structured\n",
      "   Latency: 2724ms\n",
      "   Output: **Key Points**  \n",
      "- Six counties touch this one.  \n",
      "- Marin is south; Mendocino is north.  \n",
      "- Others lie east or northeast.  \n",
      "\n",
      "**Bordering Counties**  \n",
      "- **South**: Marin  \n",
      "- **North**: Mendocino  \n",
      "- **Northeast**: Lake  \n",
      "- **East**: Napa  \n",
      "- **Southeast**: Solano and Contra Costa...\n",
      "------------------------------------------------------------\n",
      "================================================================================\n",
      "ğŸ“„ Example: asset_0 | Level: very_easy\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¹ ORIGINAL:\n",
      "Adjacent counties are Marin (to the south), Mendocino (to the north), Lake (northeast), Napa (to the...\n",
      "\n",
      "\n",
      "ğŸ”¸ qwen3-32b | generic\n",
      "   Latency: 1423ms\n",
      "   Output: <think>\n",
      "Okay, let's see. The user wants me to simplify this text about adjacent counties. The original sentence lists several counties with their directions relative to the main one. The target audience is a general audience, so I need to make it as simple as possible.\n",
      "\n",
      "First, I should break down ea...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ qwen3-32b | lexical_only\n",
      "   Latency: 1094ms\n",
      "   Output: <think>\n",
      "Okay, let's see. The user wants me to simplify the given text. The original sentence lists adjacent counties with their directions. The target level is very easy, so I need to use short sentences and simple words.\n",
      "\n",
      "First, check each part. \"Adjacent counties\" can be \"Next to the county are\" t...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ qwen3-32b | eli5\n",
      "   Latency: 1094ms\n",
      "   Output: <think>\n",
      "Okay, the user wants me to explain the given sentence as if they're five years old. Let me start by breaking down the original text. The sentence lists several counties adjacent to a main county, each with their direction. \n",
      "\n",
      "First, I need to simplify the language. Words like \"adjacent\" might...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ qwen3-32b | structured\n",
      "   Latency: 1556ms\n",
      "   Output: <think>\n",
      "Okay, the user wants me to convert the given text into a scannable format. Let me start by understanding the original text. It lists adjacent counties with their directions. The user specified key points at the start, headings, bullet points, and short sentences.\n",
      "\n",
      "First, I need to extract th...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | generic\n",
      "   Latency: 1852ms\n",
      "   Output: Here is the simplified text:\n",
      "\n",
      "The counties near here are:\n",
      "- Marin (south)\n",
      "- Mendocino (north)\n",
      "- Lake (northeast)\n",
      "- Napa (east)\n",
      "- Solano and Contra Costa (southeast)\n",
      "\n",
      "I explained:\n",
      "- \"Adjacent\" means \"near\" or \"next to\".\n",
      "- \"Counties\" are areas of land with their own governments.\n",
      "\n",
      "I used short sentence...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | lexical_only\n",
      "   Latency: 1368ms\n",
      "   Output: Nearby counties are Marin (south), Mendocino (north), Lake (northeast), Napa (east), and Solano and Contra Costa (southeast).\n",
      "\n",
      "Explanation of changes: \n",
      "- \"Adjacent\" is changed to \"Nearby\" (means close by).\n",
      "- No other complex words were found. \"North\", \"south\", \"east\", and \"northeast\" are simple dire...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | eli5\n",
      "   Latency: 3019ms\n",
      "   Output: Let's talk about neighbors.\n",
      "\n",
      "Sonoma has friends around it. \n",
      "- Marin is below Sonoma.\n",
      "- Mendocino is above Sonoma.\n",
      "- Lake is a little above and to the right.\n",
      "- Napa is to the right.\n",
      "- Solano and Contra Costa are below and to the right.\n",
      "\n",
      "\"Adjacent\" means \"next to\". \n",
      "\"Counties\" are like big neighborhoo...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ llama-4-maverick-17b-128e-instruct | structured\n",
      "   Latency: 1123ms\n",
      "   Output: **Key Points:**\n",
      "* Sonoma County has neighboring counties.\n",
      "* These counties are nearby.\n",
      "* They are listed below.\n",
      "\n",
      "**Counties Near Sonoma**\n",
      "* To the:\n",
      "  + South: Marin County\n",
      "  + North: Mendocino County\n",
      "  + Northeast: Lake County\n",
      "  + East: Napa County\n",
      "  + Southeast: Solano and Contra Costa Counties\n",
      "\n",
      "**...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | generic\n",
      "   Latency: 4248ms\n",
      "   Output: Next-door places are Marin (south), Mendocino (north), Lake (northeast), Napa (east), Solano and Contra Costa (southeast)....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | lexical_only\n",
      "   Latency: 1595ms\n",
      "   Output: Next-door counties are Marin (to the south), Mendocino (to the north), Lake (northeast), Napa (to the east), and Solano and Contra Costa (to the southeast)....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | eli5\n",
      "   Latency: 2470ms\n",
      "   Output: Think of counties like big puzzle pieces.  \n",
      "This piece touches six others.  \n",
      "Marin is the piece below.  \n",
      "Mendocino is the piece above.  \n",
      "Lake is the top-right corner.  \n",
      "Napa is the right side.  \n",
      "Solano and Contra Costa are the bottom-right corner....\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”¸ kimi-k2-instruct | structured\n",
      "   Latency: 4216ms\n",
      "   Output: Key Points  \n",
      "- Six counties touch this county.  \n",
      "- Marin is south. Mendocino is north.  \n",
      "\n",
      "Nearby Counties  \n",
      "- South: Marin  \n",
      "- North: Mendocino  \n",
      "- Northeast: Lake  \n",
      "- East: Napa  \n",
      "- Southeast: Solano and Contra Costa...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show a few example outputs to compare\n",
    "def show_sample(example_id: str, level: str = \"easy\"):\n",
    "    \"\"\"Show outputs from all models for a specific example.\"\"\"\n",
    "    subset = results_df[\n",
    "        (results_df[\"example_id\"] == example_id) & \n",
    "        (results_df[\"level\"] == level)\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ğŸ“„ Example: {example_id} | Level: {level}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Show original input\n",
    "    original = subset.iloc[0][\"input\"]\n",
    "    print(f\"\\nğŸ”¹ ORIGINAL:\\n{original}\\n\")\n",
    "    \n",
    "    # Show each model Ã— strategy output\n",
    "    for _, row in subset.iterrows():\n",
    "        print(f\"\\nğŸ”¸ {row['model'].split('/')[-1]} | {row['strategy']}\")\n",
    "        print(f\"   Latency: {row['latency_ms']:.0f}ms\")\n",
    "        print(f\"   Output: {row['output'][:300]}...\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# Show samples\n",
    "show_sample(\"asset_0\", \"easy\")\n",
    "show_sample(\"asset_0\", \"very_easy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a33f48",
   "metadata": {},
   "source": [
    "Finally something useful. But those responses are mostly bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a0754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Comparison: asset_0 | easy | eli5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– qwen3-32b (810ms):\n",
      "\n",
      "<think>\n",
      "Okay, the user wants me to explain the original sentence as if I'm talking to a 5-year-old. Let me start by breaking down the original text. It lists several counties adjacent to a main county, each with their direction. The user probably wants a simple explanation without complex words.\n",
      "\n",
      "First, I need to use very short sentences, each under 15 words. Maybe start with a main county and then mention each neighbor with their direction. Use simple terms like \"next to\" instead of \"adjacent.\"\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– llama-4-maverick-17b-128e-instruct (563ms):\n",
      "\n",
      "Here are the neighbors of this place:\n",
      "\n",
      "* Marin is below it.\n",
      "* Mendocino is above it.\n",
      "* Lake is above and to the right.\n",
      "* Napa is to the right.\n",
      "* Solano and Contra Costa are below and to the right.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– kimi-k2-instruct (756ms):\n",
      "\n",
      "Think of counties like big puzzle pieces.  \n",
      "The county touches six pieces around it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot table: compare models for a specific example + level\n",
    "def compare_models(example_id: str, level: str, strategy: str = \"generic\"):\n",
    "    \"\"\"Side-by-side model comparison.\"\"\"\n",
    "    subset = results_df[\n",
    "        (results_df[\"example_id\"] == example_id) & \n",
    "        (results_df[\"level\"] == level) &\n",
    "        (results_df[\"strategy\"] == strategy)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Comparison: {example_id} | {level} | {strategy}\\n\")\n",
    "    \n",
    "    for _, row in subset.iterrows():\n",
    "        model_name = row[\"model\"].split(\"/\")[-1]\n",
    "        print(f\"{'â”€'*60}\")\n",
    "        print(f\"ğŸ¤– {model_name} ({row['latency_ms']:.0f}ms):\\n\")\n",
    "        print(row[\"output\"][:500])\n",
    "        print()\n",
    "\n",
    "compare_models(\"asset_0\", \"easy\", \"eli5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90601b94",
   "metadata": {},
   "source": [
    "ummm... are you all ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06d00e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Average Output Length (characters):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>level</th>\n",
       "      <th>easy</th>\n",
       "      <th>medium</th>\n",
       "      <th>very_easy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-4-maverick-17b-128e-instruct</th>\n",
       "      <td>164.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonshotai/kimi-k2-instruct</th>\n",
       "      <td>135.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-32b</th>\n",
       "      <td>2044.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "level                                            easy  medium  very_easy\n",
       "model                                                                   \n",
       "meta-llama/llama-4-maverick-17b-128e-instruct   164.0   249.0      269.0\n",
       "moonshotai/kimi-k2-instruct                     135.0   150.0      173.0\n",
       "qwen/qwen3-32b                                 2044.0  1877.0     1970.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add output length as a metric\n",
    "results_df[\"output_length\"] = results_df[\"output\"].str.len()\n",
    "\n",
    "# Compare output length by model and level\n",
    "length_summary = results_df.groupby([\"model\", \"level\"])[\"output_length\"].mean().round(0)\n",
    "print(\"\\nğŸ“ Average Output Length (characters):\")\n",
    "display(length_summary.unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e968d",
   "metadata": {},
   "source": [
    "I gotta come back to this, my head hurts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbfb14f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Results saved to baseline_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV for later analysis\n",
    "results_df.to_csv(\"baseline_results.csv\", index=False)\n",
    "print(\"ğŸ’¾ Results saved to baseline_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
